{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b72228",
   "metadata": {},
   "source": [
    "## Purpose: To get assertion model prediction for cancer_imaging_findings entity\n",
    "assertion status output:\n",
    "- probability high\n",
    "- probability medium\n",
    "- probability low\n",
    "- probability uncertain"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80a7e560",
   "metadata": {},
   "source": [
    "#Notebook directory structure\n",
    "    > dataset : contains input files\n",
    "    > saved_models : contains output assertion models\n",
    "    > assertion_output : model predictions\n",
    "    > assertion_result : performance metrics\n",
    "    > training_logs : training logs\n",
    "    > tf_graphs : tensorflow graph file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baef2923",
   "metadata": {},
   "source": [
    "### Note: Before running this notebook, please configure the following paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a449be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using sparknlp clinical embedding word model\n",
    "# specify your folder containing the downloaded clinical embedding word model file, or you can use .pretrained during training instead to load it online\n",
    "embeddings_clinical_local_path = r\"path\\to\\sparknlp_pretrained\\embeddings_clinical_en_2.4.0_2.4_1580237286004\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da97d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your sparknlp online license key-need internet connection\n",
    "# we are using v3.4.2\n",
    "sparknlp_licence_key = r\"..\\sparknlp_licence_key\\yourkey.json\"\n",
    "\n",
    "# specify your sparknlp offline license key-airgap env\n",
    "# we are using v3.4.2\n",
    "sparknlp_airgap_licence_key = r\"..\\sparknlp_licence_key\\yourairgapkey.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b105567",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5f363",
   "metadata": {},
   "source": [
    "Note: Requires Spark NLP and Spark NLP for Healthcare (licensed version) packages to be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd737e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, re, sparknlp, sparknlp_jsl, datetime, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.training import CoNLL\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp_jsl.training import tf_graph\n",
    "from sparknlp_display import AssertionVisualizer, NerVisualizer \n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e6ea39",
   "metadata": {},
   "source": [
    "Note: Requires Spark NLP for Healthcare (licensed version) license key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdacb53",
   "metadata": {},
   "source": [
    "### Start Spark Session (Offline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f565807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offline-Load airgap license key\n",
    "with open(sparknlp_airgap_licence_key) as f:\n",
    "    airgap_license_keys = json.load(f)\n",
    "    \n",
    "# Defining license key-value pairs as local variables\n",
    "locals().update(airgap_license_keys)\n",
    "os.environ.update(airgap_license_keys)\n",
    "\n",
    "# check variable\n",
    "!echo $SECRET\n",
    "!echo $JSL_VERSION\n",
    "!echo $PUBLIC_VERSION\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "print(os.environ['PYSPARK_PYTHON'])\n",
    "print(os.environ['PYSPARK_DRIVER_PYTHON'])\n",
    "\n",
    "# Start Spark Session with Custom Params (OFFLINE)\n",
    "def start(SECRET):\n",
    "    builder = SparkSession.builder \\\n",
    "        .appName(\"Spark NLP Licensed radio_assertion\") \\\n",
    "        .master(\"local[16]\") \\\n",
    "        .config(\"spark.driver.memory\", \"16G\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "        .config(\"spark.driver.maxResultSize\",\"4000M\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.4.2\") \\\n",
    "        .config(\"spark.jars\", f\"d:\\content\\spark-nlp-jsl-{JSL_VERSION}.jar, d:\\content\\spark-nlp_2.12-3.4.2.jar\" )\n",
    "\n",
    "    return builder.getOrCreate()\n",
    "\n",
    "\n",
    "print(\"Spark NLP Version :\", sparknlp.version())\n",
    "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
    "\n",
    "spark = start(SECRET) \n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b33867",
   "metadata": {},
   "source": [
    "### Start Spark Session (Online)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bca30290",
   "metadata": {},
   "source": [
    "# Load license key\n",
    "with open(sparknlp_licence_key) as f:\n",
    "    license_keys = json.load(f)\n",
    "license_keys.keys()\n",
    "\n",
    "# Defining license key-value pairs as local variables\n",
    "locals().update(license_keys)\n",
    "\n",
    "# Adding license key-value pairs to environment variables, use this (17-Aug-2022)\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0c857eb",
   "metadata": {},
   "source": [
    "## 17-Aug-2022: try this, this is working\n",
    "# Start Spark Session\n",
    "params = {\"spark.master\":\"local[16]\",\n",
    "          \"spark.driver.memory\":\"16G\", \n",
    "          \"spark.executor.memory\":\"2G\",\n",
    "          \"spark.kryoserializer.buffer.max\":\"2000M\", \n",
    "          \"spark.driver.maxResultSize\":\"4000M\",\n",
    "          \"spark.serializer\":\"org.apache.spark.serializer.KryoSerializer\",\n",
    "          \"spark.jars.packages\": \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.4.2\",\n",
    "          \"spark.jars\": \"https://pypi.johnsnowlabs.com/\"+SECRET+\"/spark-nlp-jsl-\"+JSL_VERSION+\".jar\",\n",
    "          \"spark.local.dir\": r\"c:\\users\\guathwa\\spark-temp\"\n",
    "           } \n",
    "\n",
    "print(\"Spark NLP Version :\", sparknlp.version())\n",
    "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
    "\n",
    "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "raw",
   "id": "81d4afaf",
   "metadata": {},
   "source": [
    "# check variable\n",
    "#!echo $SECRET\n",
    "!echo $JSL_VERSION\n",
    "!echo $PUBLIC_VERSION\n",
    "#!echo $SPARK_NLP_LICENSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a06254",
   "metadata": {},
   "source": [
    "## ------------------- MODEL INFERENCE --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa7091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the name of your NER model\n",
    "radio_ner_model = \"clinical_embeddings_5_8_0.001_u0.4o1_train4522\"\n",
    "\n",
    "# specify the name of your Assertion model\n",
    "assertion_model_name = \"radio_assertion_model_20_16_0.001_2023_04_21_16_19_46_train4522\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9288cc6c",
   "metadata": {},
   "source": [
    "# 4. Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "document = DocumentAssembler()\\\n",
    "        .setInputCol(\"text\")\\\n",
    "        .setOutputCol(\"document\")\n",
    "\n",
    "sentence = SentenceDetector()\\\n",
    "        .setInputCols(['document'])\\\n",
    "        .setOutputCol('sentences')\n",
    "\n",
    "token = Tokenizer()\\\n",
    "        .setInputCols(['sentences'])\\\n",
    "        .setOutputCol('tokens')\n",
    "\n",
    "words_embedder = WordEmbeddingsModel()\\\n",
    "    .load(embeddings_clinical_local_path)\\\n",
    "    .setInputCols([\"sentences\", \"tokens\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "  \n",
    "radio_ner_tagger = MedicalNerModel.load(radio_ner_model)\\\n",
    "    .setInputCols([\"sentences\", \"tokens\", \"embeddings\"])\\\n",
    "    .setOutputCol(\"ner_tags\")\n",
    "\n",
    "converter = NerConverter()\\\n",
    "        .setInputCols([\"sentences\", \"tokens\", \"ner_tags\"])\\\n",
    "        .setOutputCol(\"ner_span\")\\\n",
    "        .setWhiteList([\"cancer_imaging_findings\"])\n",
    "\n",
    "## add radio assertion model\n",
    "radiology_assertion = AssertionDLModel.load('./saved_models/'+'/'+assertion_model_name) \\\n",
    "    .setInputCols([\"sentences\", \"ner_span\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "\n",
    "ner_assertion_pipeline = Pipeline(stages = [\n",
    "        document,\n",
    "        sentence,\n",
    "        token,\n",
    "        words_embedder,\n",
    "        radio_ner_tagger,\n",
    "        converter,\n",
    "        radiology_assertion\n",
    "])\n",
    "\n",
    "empty_data = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "\n",
    "ner_assertion_model = ner_assertion_pipeline.fit(empty_data)\n",
    "\n",
    "lmodel = LightPipeline(ner_assertion_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbed8701",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6eb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# site of mets\n",
    "mtext1 = \"\"\"\n",
    "your sample text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4544f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = mtext1\n",
    "sample_data = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "sample_data.show(truncate=False)\n",
    "sample_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad8199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ner_assertion_model.transform(sample_data)\n",
    "\n",
    "preds.select(F.explode(F.arrays_zip(\"ner_span.result\",\"ner_span.metadata\")).alias(\"entities\")) \\\n",
    ".select(F.expr(\"entities['0']\").alias(\"chunk\"),\n",
    "        F.expr(\"entities['1'].entity\").alias(\"entity\")).show(50,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce39c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.select(F.explode(F.arrays_zip(preds.ner_span.result, \n",
    "                                     preds.ner_span.metadata, \n",
    "                                     preds.assertion.result)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"chunks\"),\n",
    "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\"),\n",
    "              F.expr(\"cols['1']['sentences']\").alias(\"sent_id\"),\n",
    "              F.expr(\"cols['2']\").alias(\"assertion\")).show(50,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085dea44",
   "metadata": {},
   "source": [
    "## LightPipeline / Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mkdir display_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab375c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppres = lmodel.fullAnnotate(text)[0]\n",
    "ppres.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9debc79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sparknlp_display import NerVisualizer\n",
    "visualiser = NerVisualizer()\n",
    "visualiser.display(ppres, label_col='ner_span', document_col='document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b558ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertion_vis = AssertionVisualizer()\n",
    "assertion_vis.display(ppres, 'ner_span', 'assertion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfe21a7",
   "metadata": {},
   "source": [
    "## Get prediction with sample.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575836db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the column names accordinlgy to suit your dataset\n",
    "df_text = pd.read_csv(\"./inference/samples.csv\", usecols=['sn_report_number', 'report_date','findings','conclusion'])\n",
    "df_text.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb236ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30958534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null text\n",
    "df_text.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29631f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null\n",
    "df_text['conclusion'] = df_text['conclusion'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c5c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the visualisation to html file for review\n",
    "# save the annotation to csv for review\n",
    "annotation_df = pd.DataFrame()\n",
    "for i in range(df_text['sn_report_number'].count()):\n",
    "    print(i)\n",
    "    ppres = lmodel.fullAnnotate(df_text['conclusion'].loc[i])[0]\n",
    "    assertion_vis.display(ppres, 'ner_span', 'assertion',save_path=\"./inference/display_result/\"+df_text['sn_report_number'].loc[i]+\"_report.html\")\n",
    "    #output to csv\n",
    "    chunk=[]\n",
    "    entity=[]\n",
    "    status=[]\n",
    "    for n,m in zip(ppres['ner_span'],ppres['assertion']):\n",
    "        chunk.append(n.result)\n",
    "        entity.append(n.metadata['entity']) \n",
    "        status.append(m.result)\n",
    "    temp_df = pd.DataFrame({'sn_report_number':df_text['sn_report_number'].loc[i],'report_date':df_text['report_date'].loc[i],'chunk':chunk, 'entity':entity, 'assertion_status':status})    \n",
    "    temp_df['entity_index'] = temp_df.index\n",
    "    #print(temp_df)\n",
    "    annotation_df = annotation_df.append(temp_df)\n",
    "    #print(annotation_df)\n",
    "\n",
    "columns = ['sn_report_number', 'report_date','entity_index', 'entity','chunk','assertion_status']\n",
    "annotation_df.to_csv(\"./inference/display_result/sample_ner_assertion.csv\", columns=columns, index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f4c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf38fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
