{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a43e795b",
   "metadata": {},
   "source": [
    "## Purpose: Get Radio NER Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baef2923",
   "metadata": {},
   "source": [
    "### Note: Before running this notebook, please configure the following paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa4118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using sparknlp clinical embedding word model\n",
    "# specify your folder containing the downloaded clinical embedding word model file, or you can use .pretrained during training instead to load it online\n",
    "embeddings_clinical_local_path = r\"path\\to\\sparknlp_pretrained\\embeddings_clinical_en_2.4.0_2.4_1580237286004\"\n",
    "\n",
    "# we are using sparknlp radiology assertion model\n",
    "# specify your folder containing the downloaded jsl assertion model file, or you can use .pretrained during training instead to load it online\n",
    "jsl_radiology_assertion = r\"path\\to\\sparknlp_pretrained\\assertion_dl_radiology_en_2.7.4_2.4_1616071311532\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da97d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your sparknlp online license key-need internet connection\n",
    "# we are using v3.4.2\n",
    "sparknlp_licence_key = r\"..\\sparknlp_licence_key\\yourkey.json\"\n",
    "\n",
    "# specify your sparknlp offline license key-airgap env\n",
    "# we are using v3.4.2\n",
    "sparknlp_airgap_licence_key = r\"..\\sparknlp_licence_key\\yourairgapkey.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b105567",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5f363",
   "metadata": {},
   "source": [
    "Note: Requires Spark NLP and Spark NLP for Healthcare (licensed version) packages to be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd737e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, re, sparknlp, sparknlp_jsl, ner_log_parser, datetime, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.training import CoNLL\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp_jsl.training import tf_graph\n",
    "from sparknlp_display import AssertionVisualizer, NerVisualizer \n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdacb53",
   "metadata": {},
   "source": [
    "# 2. Start Spark Session (OFFLINE for inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d9a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offline-Load airgap license key\n",
    "with open(sparknlp_airgap_licence_key) as f:\n",
    "    airgap_license_keys = json.load(f)\n",
    "    \n",
    "# Defining license key-value pairs as local variables\n",
    "locals().update(airgap_license_keys)\n",
    "\n",
    "# Adding license key-value pairs to environment variables, use this (17-Aug-2022)\n",
    "os.environ['SPARK_NLP_LICENSE'] = airgap_license_keys['SPARK_NLP_LICENSE']\n",
    "\n",
    "# check variable\n",
    "#!echo $SECRET\n",
    "!echo $JSL_VERSION\n",
    "!echo $PUBLIC_VERSION\n",
    "#!echo $SPARK_NLP_LICENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ba57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your downloaded spark nlp jar files in a local folder, eg d:\\content\n",
    "# note path cannot be too long, else there will be a java error on package not callable\n",
    "\n",
    "def start(SECRET):\n",
    "    builder = SparkSession.builder \\\n",
    "        .appName(\"Spark NLP Licensed radio ner\") \\\n",
    "        .master(\"local[16]\") \\\n",
    "        .config(\"spark.driver.memory\", \"16G\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.4.2\") \\\n",
    "        .config(\"spark.jars\", f\"d:\\content\\spark-nlp-jsl-{JSL_VERSION}.jar, d:\\content\\spark-nlp_2.12-3.4.2.jar\" )\n",
    "\n",
    "    return builder.getOrCreate()\n",
    "\n",
    "\n",
    "print(\"Spark NLP Version :\", sparknlp.version())\n",
    "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
    "\n",
    "spark = start(SECRET) \n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3a2a8b",
   "metadata": {},
   "source": [
    "# 3. Create NER Prediction Pipeline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee64f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is saved during NER training\n",
    "best_ner_model = \"clinical_embeddings_1_8_0.001_u0.3o1_train4522\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34699c81",
   "metadata": {},
   "source": [
    "## Prediction Pipeline - with jsl assertion status detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d518ff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading\n",
    "document = DocumentAssembler()\\\n",
    "        .setInputCol(\"text\")\\\n",
    "        .setOutputCol(\"document\")\n",
    "\n",
    "sentence = SentenceDetector()\\\n",
    "        .setInputCols(['document'])\\\n",
    "        .setOutputCol('sentence')\n",
    "\n",
    "token = Tokenizer()\\\n",
    "        .setInputCols(['sentence'])\\\n",
    "        .setOutputCol('token')\n",
    "\n",
    "#use .pretrained() for sparknlp online session\n",
    "#use .load() for sparknlp airgap session\n",
    "clinical_embeddings = WordEmbeddingsModel.load(embeddings_clinical_local_path)\\\n",
    "    .setInputCols([\"sentence\",\"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "#load the best ner model saved after training\n",
    "loaded_ner_model = MedicalNerModel.load(\"./saved_models/\" + best_ner_model)\\\n",
    "        .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
    "        .setOutputCol(\"ner\")\n",
    "\n",
    "converter = NerConverter()\\\n",
    "        .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
    "        .setOutputCol(\"ner_span\")\n",
    "\n",
    "#using jsl radiology assertion model for all ner entities \n",
    "#use .pretrained() for sparknlp online session\n",
    "#use .load() for sparknlp airgap session\n",
    "#radiology_assertion = AssertionDLModel.pretrained(\"assertion_dl_radiology\", \"en\", \"clinical/models\") \\\n",
    "radiology_assertion = AssertionDLModel.load(\"./assertion_dl_radiology_en_2.7.4_2.4_1616071311532\")\\\n",
    "    .setInputCols([\"sentence\", \"ner_span\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "\n",
    "ner_prediction_pipeline = Pipeline(stages = [\n",
    "        document,\n",
    "        sentence,\n",
    "        token,\n",
    "        clinical_embeddings,\n",
    "        loaded_ner_model,\n",
    "        converter,\n",
    "        radiology_assertion\n",
    "])\n",
    "\n",
    "empty_data = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "\n",
    "ner_prediction_model = ner_prediction_pipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cc83e0",
   "metadata": {},
   "source": [
    "## Sample prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b28ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"\n",
    "your sample text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4544f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text1\n",
    "sample_data = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "sample_data.show()\n",
    "sample_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad8199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ner_prediction_model.transform(sample_data)\n",
    "\n",
    "preds.select(F.explode(F.arrays_zip(\"ner_span.result\",\"ner_span.metadata\")).alias(\"entities\")) \\\n",
    ".select(F.expr(\"entities['0']\").alias(\"chunk\"),\n",
    "        F.expr(\"entities['1'].entity\").alias(\"entity\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085dea44",
   "metadata": {},
   "source": [
    "## LightPipeline / Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab375c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmodel = LightPipeline(ner_prediction_model)\n",
    "ppres = lmodel.fullAnnotate(text)[0]\n",
    "ppres.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppres['ner_span']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c36286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertion detection\n",
    "chunks=[]\n",
    "entities=[]\n",
    "status=[]\n",
    "\n",
    "for n,m in zip(ppres['ner_span'],ppres['assertion']):\n",
    "    \n",
    "    chunks.append(n.result)\n",
    "    entities.append(n.metadata['entity']) \n",
    "    status.append(m.result)\n",
    "        \n",
    "df = pd.DataFrame({'chunks':chunks, 'entities':entities, 'assertion':status})\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9debc79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sparknlp_display import NerVisualizer\n",
    "visualiser = NerVisualizer()\n",
    "\n",
    "# Set label filter\n",
    "visualiser.display(ppres, label_col='ner_span', document_col='document', save_path=\"./inference/display_result/display_result.html\")\n",
    "df.to_csv(\"./inference/display_result/display_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b558ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dfe21a7",
   "metadata": {},
   "source": [
    "## Get prediction with input csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575836db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the codes accordingly based on your csv file\n",
    "# it should contain a text column \"conclusion\"\n",
    "df_text = pd.read_csv(\"./inference/50samples.csv\", usecols=['sn_report_number','report','report_date','conclusion'])\n",
    "df_text.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb236ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c692698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null text\n",
    "df_text.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null\n",
    "df_text['conclusion'] = df_text['conclusion'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514a8146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the ner visualisation to html file for review\n",
    "# save the ner annotation to csv for review\n",
    "\n",
    "annotation_df = pd.DataFrame()\n",
    "for i in range(df_text['sn_report_number'].count()):\n",
    "    print(i)\n",
    "    ppres = lmodel.fullAnnotate(df_text['conclusion'].loc[i])[0]\n",
    "    visualiser.display(ppres, label_col='ner_span', document_col='document', save_path=\"./inference/display_result/\"+df_text['sn_report_number'].loc[i]+\"_report.html\")\n",
    "\n",
    "    #output to csv\n",
    "    chunk=[]\n",
    "    entity=[]\n",
    "    status=[]\n",
    "    for n,m in zip(ppres['ner_span'],ppres['assertion']):\n",
    "        chunk.append(n.result)\n",
    "        entity.append(n.metadata['entity']) \n",
    "        status.append(m.result)\n",
    "    temp_df = pd.DataFrame({'sn_report_number':df_text['sn_report_number'].loc[i],'report_date':df_text['report_date'].loc[i],'chunk':chunk, 'entity':entity, 'assertion_status':status})    \n",
    "    temp_df['entity_index'] = temp_df.index\n",
    "    #print(temp_df)\n",
    "    annotation_df = annotation_df.append(temp_df)\n",
    "    #print(annotation_df)\n",
    "\n",
    "columns = ['sn_report_number', 'report_date','entity_index', 'entity','chunk','assertion_status']\n",
    "annotation_df.to_csv(\"./inference/display_result/pred_radio_ner_annotation.csv\", columns=columns, index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b8aa48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c5c9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
